{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import queue\n",
    "from collections import defaultdict\n",
    "\n",
    "import nltk\n",
    "%matplotlib inline\n",
    "\n",
    "from ipynb.fs.full.log_entries import get_all_log_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def full_group_by(l, key=lambda x: x):\n",
    "    d = defaultdict(list)\n",
    "    for item in l:\n",
    "        d[key(item)].append(item)\n",
    "    return d.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def is_complete(token_position_cardinalities, group_uniqueness_threshold):\n",
    "    group_len = len(token_position_cardinalities)\n",
    "    complete_token_positions = 0\n",
    "    for token_position_cardinality in token_position_cardinalities:\n",
    "        if token_position_cardinality == 1:\n",
    "            complete_token_positions += 1\n",
    "    group_determinant = complete_token_positions / group_len\n",
    "    if group_determinant > group_uniqueness_threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def count_unique_tokens_at_each_token_position(group):\n",
    "    group_len = len(group[0])\n",
    "    token_position_cardinality = []\n",
    "    for token_position in range(group_len):\n",
    "        unique_tokens_at_current_position = {tokens[token_position] for tokens in group}\n",
    "        token_position_cardinality.append(len(unique_tokens_at_current_position))\n",
    "    return token_position_cardinality\n",
    "\n",
    "def convert_to_msg_template(group, token_position_cardinalities):\n",
    "    group_representative = group[0]\n",
    "    msg_template = []\n",
    "    for i in range(len(group_representative)):\n",
    "        if token_position_cardinalities[i] == 1:\n",
    "            msg_template.append(group_representative[i])\n",
    "        else:\n",
    "            msg_template.append('*')\n",
    "    return group, len(group)\n",
    "\n",
    "def determine_log_msg_templates(tokenized_msg_groups_by_length, \n",
    "                                group_uniqueness_threshold,\n",
    "                                absolute_threshold,\n",
    "                                relative_threshold):\n",
    "    \n",
    "    incomplete_groups_queue = queue.Queue()\n",
    "    for group in tokenized_msg_groups_by_length:\n",
    "        incomplete_groups_queue.put(group)\n",
    "    \n",
    "    complete_groups = []\n",
    "    incomplete_groups = []\n",
    "    while not incomplete_groups_queue.empty():\n",
    "        current_group = incomplete_groups_queue.get()\n",
    "        token_position_cardinalities = count_unique_tokens_at_each_token_position(current_group)\n",
    "        if is_complete(token_position_cardinalities, group_uniqueness_threshold):\n",
    "            complete_groups.append(convert_to_msg_template(current_group, token_position_cardinalities))\n",
    "        else:\n",
    "            lowest_token_position_cardinality = min(token_position_cardinalities)\n",
    "            split_token_position = token_position_cardinalities.index(lowest_token_position_cardinality)\n",
    "            AT = lowest_token_position_cardinality\n",
    "            RT = lowest_token_position_cardinality / len(current_group)\n",
    "            if AT > absolute_threshold and RT > relative_threshold:\n",
    "                complete_groups.append(convert_to_msg_template(current_group, token_position_cardinalities))\n",
    "            else:\n",
    "                grouped_by_split_token_position = full_group_by(current_group, lambda x: x[split_token_position])\n",
    "                for subgroup in grouped_by_split_token_position:\n",
    "                    subgroup_elements = subgroup[1]\n",
    "                    subgroup_token_position_cardinalities = count_unique_tokens_at_each_token_position(subgroup_elements)\n",
    "                    if is_complete(subgroup_token_position_cardinalities, group_uniqueness_threshold):\n",
    "                        complete_groups.append(convert_to_msg_template(subgroup_elements, subgroup_token_position_cardinalities))\n",
    "                    else:\n",
    "                        if len(grouped_by_split_token_position) > 1:\n",
    "                            incomplete_groups_queue.put(subgroup_elements)\n",
    "                        else:\n",
    "                            incomplete_groups.append(convert_to_msg_template(subgroup_elements, subgroup_token_position_cardinalities))\n",
    "    return complete_groups, incomplete_groups\n",
    "\n",
    "def determine_log_msg_templates_from_logs_starting_with(filename_prefix,\n",
    "                                group_uniqueness_threshold = 0.6,\n",
    "                                absolute_threshold = 10,\n",
    "                                relative_threshold = 0.1):\n",
    "    entries = get_all_log_entries(filename_prefix)\n",
    "    tokenized_msgs = [*map(lambda x: nltk.word_tokenize(x['msg']), entries)]\n",
    "    grouped_by_length = [entry[1] for entry in full_group_by(tokenized_msgs, lambda x: len(x))]\n",
    "    return determine_log_msg_templates(grouped_by_length, \n",
    "                                       group_uniqueness_threshold = group_uniqueness_threshold,\n",
    "                                       absolute_threshold = absolute_threshold,\n",
    "                                       relative_threshold = relative_threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}